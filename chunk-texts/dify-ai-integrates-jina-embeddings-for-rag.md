# dify-ai-integrates-jina-embeddings-for-rag

## SIMPLE_CHUNKING

#### 2 chunk(s)

Integrating Embeddings in RAG Current AI architecturestoday have no direct way to integrate outside information sources. The model itself encodes information from its training data with varying levels of accuracy, and it is impractical to retrain the model every time there is new, potentially useful data that could be incorporated into it. For example, I asked JinaChat a question about current events: The only way to ensure that an LLM has the information needed to answer a factual question is to provide it in the prompt: Naturally, an LLM that only answers questions correctly if you include the answer in your question isn’t very useful. This has led to a body of techniques called Retrieval-Augmented Generation or RAG. RAG is a framework installed around an LLM that searches external information sources for materials that might contain the information needed to answer a user’s request and then presents them, with the user’s prompt, to the LLM. This strategy has the added benefit that LLMs hallucinate much less when they are expected to handle a given text rather than recall things they might partially remember from training. Leveraging Jina Embeddings Superior Performance Dify.AI has integrated Jina Embeddings v2 to enhance retrieval quality for RAG prompting. Jina AI’s models provide state-of-the-art accuracy in RAG applications, and with an input window of 8,192 tokens, they can support much larger and more complex questions than most competing models at a much lower price.

August 26, 2024 • 13 minutes read The What and Why of Text-Image Modality Gap in CLIP Models You can't just use a CLIP model to retrieve text and images and sort the results by score. Why? Because of the modality gap. What is it, and where does it come from? August 22, 2024 • 8 minutes read Late Chunking in Long-Context Embedding Models Chunking long documents while preserving contextual information is challenging. We introduce the "Late Chunking" that leverages long-context embedding models to generate contextual chunk embeddings for better retrieval applications. July 31, 2024 • 17 minutes read Rephrased Labels Improve Zero-Shot Text Classification by 30% When using embedding models for zero-shot classification, rephrasing the class label to "This is seriously about 'LABEL'" gives higher accuracy vs. using LABEL alone. But how, and why? OFFICES location_on Berlin, Germany (HQ) Prinzessinnenstraße 19-20, 10969 Berlin, Germany Geschäftsanschrift: Leipzigerstr. 96, 10117 Berlin, Germany location_on Beijing, China Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China location_on Shenzhen, China 402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China SEARCH FOUNDATION Embeddings Reranker Reader Segmenter Get Jina AI API key API Status COMPANY About us Contact sales Newsroom Intern program Join us open_in_new Download logo open_in_new TERMS Terms & Conditions Privacy Manage Cookies email language English science Jina AI GmbH © 2020-2024.

## COT_TOPIC_CHUNKING

#### 6 chunk(s)

Dify.AI · The Innovation Engine for Generative AI Applications The next-gen development platform - Easily build and operate generative AI applications. Create Assistants API and GPTs based on any LLMs. Embedding API Top-performing, 8192-token length, $100 for 1.25B tokens, seamless OpenAI alternative, free trial For more information about Jina AI’s offerings, check out the Jina AI website or join our community on Discord. Join the Jina AI Discord Server! Check out the Jina AI community on Discord - hang out with 3873 other members and enjoy free voice and text chat. Discord Categories: Tech blog rss_feed Top-5 similar articles play_arrow GET TOP-5 Select reranker Read more

August 26, 2024 • 13 minutes read The What and Why of Text-Image Modality Gap in CLIP Models

You can't just use a CLIP model to retrieve text and images and sort the results by score. Why? Because of the modality gap. What is it, and where does it come from? August 22, 2024 • 8 minutes read

Late Chunking in Long-Context Embedding Models Chunking long documents while preserving contextual information is challenging. We introduce the "Late Chunking" that leverages long-context embedding models to generate contextual chunk embeddings for better retrieval applications. July 31, 2024 • 17 minutes read Rephrased Labels Improve Zero-Shot Text Classification by 30% When using embedding models for zero-shot classification, rephrasing the class label to "This is seriously about 'LABEL'" gives higher accuracy vs. using LABEL alone. But how, and why?

OFFICES location_on Berlin, Germany (HQ) Prinzessinnenstraße 19-20, 10969 Berlin, Germany Geschäftsanschrift: Leipzigerstr. 96, 10117 Berlin, Germany location_on Beijing, China Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China location_on Shenzhen, China 402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China SEARCH FOUNDATION Embeddings Reranker Reader Segmenter Get Jina AI API key API Status COMPANY About us Contact sales Newsroom Intern program Join us open_in_new Download logo open_in_new TERMS Terms & Conditions Privacy Manage Cookies email language English science

Jina AI GmbH © 2020-2024.

## SUMMARY_CHUNKING

#### 2 chunk(s)

search notifications NEWS PRODUCTS COMPANY Tech blog December 06, 2023 Dify.AI integrates Jina Embeddings for RAG

location_on Berlin, Germany (HQ) Prinzessinnenstraße 19-20, 10969 Berlin, Germany Geschäftsanschrift: Leipzigerstr. 96, 10117 Berlin, Germany location_on Beijing, China Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China location_on Shenzhen, China 402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China SEARCH FOUNDATION Embeddings Reranker Reader Segmenter Get Jina AI API key API Status COMPANY About us Contact sales Newsroom Intern program Join us open_in_new Download logo open_in_new TERMS Terms & Conditions Privacy Manage Cookies email language English science Jina AI GmbH © 2020-2024.

## JINA-SEGMENTER-API

#### 91 chunk(s)

search


notifications


NEWS


PRODUCTS


COMPANY


Tech blog


December 06, 2023


Dify.AI integrates Jina Embeddings for RAG


Dify.AI, a leading open-source platform specialized in creating generative AI applications, is now leveraging Jina Embeddings v2!


Scott Martens • 3 minutes read



Online LLM application development platform Dify.AI has integrated the Jina Embeddings v2 API in its innovative AI toolkit for instant access when building and hosting LLM applications. All you need to do is add your Jina Embeddings API key via their intuitive web interface to get the full power of Jina AI’s industry-leading embedding models in your RAG (retrieval-augmented generation) applications.



Dify.AI x Jina AI：Dify now Integrates Jina Embedding Model - Dify Blog


The next-gen development platform - Easily build and operate generative AI applications. Create Assistants API and GPTs based on any LLMs.


Dify Blog


Embedding API


Top-performing, 8192-token length, $100 for 1.25B tokens, seamless OpenAI alternative, free trial


Integrating Embeddings in RAG



Current AI architectures today have no direct way to integrate outside information sources. The model itself encodes information from its training data with varying levels of accuracy, and it is impractical to retrain the model every time there is new, potentially useful data that could be incorporated into it.



For example, I asked JinaChat a question about current events:



The only way to ensure that an LLM has the information needed to answer a factual question is to provide it in the prompt:



Naturally, an LLM that only answers questions correctly if you include the answer in your question isn’t very useful. This has led to a body of techniques called Retrieval-Augmented Generation or RAG. RAG is a framework installed around an LLM that searches external information sources for materials that might contain the information needed to answer a user’s request and then presents them, with the user’s prompt, to the LLM.



This strategy has the added benefit that LLMs hallucinate much less when they are expected to handle a given text rather than recall things they might partially remember from training.



Leveraging Jina Embeddings Superior Performance



Dify.AI has integrated Jina Embeddings v2 to enhance retrieval quality for RAG prompting. Jina AI’s models provide state-of-the-art accuracy in RAG applications, and with an input window of 8,192 tokens, they can support much larger and more complex questions than most competing models at a much lower price.



You can now use Jina Embeddings in your LLM projects via Dify.AI’s intuitive application builder, as shown in the video below or in the post on Dify.AI's blog:



0:00


/0:38


1×


Get Involved



Check out Dify.AI’s LLM application builder and hosting service for yourself. You can get a free tester token from the Jina AI website to use Jina Embeddings to try it out.



Dify.AI · The Innovation Engine for Generative AI Applications


The next-gen development platform - Easily build and operate generative AI applications. Create Assistants API and GPTs based on any LLMs.


Embedding API


Top-performing, 8192-token length, $100 for 1.25B tokens, seamless OpenAI alternative, free trial



For more information about Jina AI’s offerings, check out the Jina AI website or join our community on Discord.



Join the Jina AI Discord Server!


Check out the Jina AI community on Discord - hang out with 3873 other members and enjoy free voice and text chat.


Discord


Categories:


Tech blog


rss_feed


Top-5 similar articles


play_arrow


GET TOP-5


Select reranker


Read more


August 26, 2024 • 13 minutes read


The What and Why of Text-Image Modality Gap in CLIP Models


You can't just use a CLIP model to retrieve text and images and sort the results by score. Why? Because of the modality gap. What is it, and where does it come from?


August 22, 2024 • 8 minutes read


Late Chunking in Long-Context Embedding Models


Chunking long documents while preserving contextual information is challenging. We introduce the "Late Chunking" that leverages long-context embedding models to generate contextual chunk embeddings for better retrieval applications.


July 31, 2024 • 17 minutes read


Rephrased Labels Improve Zero-Shot Text Classification by 30%


When using embedding models for zero-shot classification, rephrasing the class label to "This is seriously about 'LABEL'" gives higher accuracy vs. using LABEL alone. But how, and why?


OFFICES


location_on


Berlin, Germany (HQ)


Prinzessinnenstraße 19-20, 10969 Berlin, Germany


Geschäftsanschrift: Leipzigerstr. 96, 10117 Berlin, Germany


location_on


Beijing, China


Level 5, Building 6, No.48 Haidian West St. Beijing Haidian, China


location_on


Shenzhen, China


402, Floor 4, Fu'an Technology Building, Shenzhen Nanshan, China


SEARCH FOUNDATION


Embeddings


Reranker


Reader


Segmenter


Get Jina AI API key


API Status


COMPANY


About us


Contact sales


Newsroom


Intern program


Join us


open_in_new


Download logo


open_in_new


TERMS


Terms & Conditions


Privacy


Manage Cookies


email


language


English


science


Jina AI GmbH © 2020-2024.

---