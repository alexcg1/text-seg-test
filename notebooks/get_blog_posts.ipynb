{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb42b80-51bf-4399-8b84-74814dd8e072",
   "metadata": {},
   "source": [
    "## Get blog posts\n",
    "\n",
    "- Extract markdown from Jina blog posts\n",
    "- Convert to plain text\n",
    "- Store in one big string to send to GPT later (for generating questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ade5b8-724e-4eb6-a03d-6642523e53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4b8466-6aa9-4e3a-b837-d31941d361be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first ten pages of jina.ai/news, excluding docarray/jina release posts (which are all very samey and basic)\n",
    "urls = [\n",
    "    \"https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown\",\n",
    "    \"https://jina.ai/news/jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking\",\n",
    "    \"https://jina.ai/news/late-chunking-in-long-context-embedding-models\",\n",
    "    \"https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models\",\n",
    "    \"https://jina.ai/news/by-hoovering-up-the-web-ai-is-poisoning-itself\",\n",
    "    \"https://jina.ai/news/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc\",\n",
    "    \"https://jina.ai/news/jina-embeddings-and-reranker-on-azure-scalable-business-ready-ai-solutions\",\n",
    "    \"https://jina.ai/news/having-it-both-ways-combining-bm25-with-ai-reranking\",\n",
    "    \"https://jina.ai/news/smaller-faster-cheaper-jina-rerankers-turbo-and-tiny\",\n",
    "    \"https://jina.ai/news/enhancing-search-results-with-jina-ais-reranker-api-in-myscale\",\n",
    "    \"https://jina.ai/news/retrieve-jira-tickets-with-jina-reranker-and-haystack-20\",\n",
    "    \"https://jina.ai/news/dspy-not-your-average-prompt-engineering\",\n",
    "    \"https://jina.ai/news/elevating-youtube-scripts-with-promptperfect-ai-mastery-for-video-content-creators\",\n",
    "    \"https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker\",\n",
    "    \"https://jina.ai/news/click-worthy-content-with-promptperfect-ai-marketing-for-newsletters-and-social-media\",\n",
    "    \"https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker\",\n",
    "    \"https://jina.ai/news/revolutionizing-bilingual-text-embeddings-with-multi-task-contrastive-learning\",\n",
    "    \"https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search\",\n",
    "    \"https://jina.ai/news/theres-a-time-and-a-place-unleashing-dynamic-variables-in-promptperfect\",\n",
    "    \"https://jina.ai/news/dify-ai-integrates-jina-embeddings-for-rag\",\n",
    "    \"https://jina.ai/news/jina-embeddings-v2-and-mongodb-atlas\",\n",
    "    \"https://jina.ai/news/scenexplains-json-schema-store-automate-your-alt-text-and-more\",\n",
    "    \"https://jina.ai/news/artificial-general-intelligence-is-cursed-and-science-fiction-isnt-helping\",\n",
    "    \"https://jina.ai/news/jina-ai-8k-embedding-models-hit-aws-marketplace-for-on-prem-deployment\",\n",
    "    \"https://jina.ai/news/scenexplains-ocr-beats-gpt-4v-hands-down-chinese-japanese-korean-arabic-hindi-and-more\",\n",
    "    \"https://jina.ai/news/embeddings-in-depth\",\n",
    "    \"https://jina.ai/news/look-up-in-the-sky-using-scenexplain-to-classify-land-use-from-satellite-data\",\n",
    "    \"https://jina.ai/news/jina-embeddings-2-the-best-solution-for-embedding-long-documents\",\n",
    "    \"https://jina.ai/news/case-study-revolutionizing-e-commerce-user-experience-and-streamlining-search-with-scenexplain\",\n",
    "    \"https://jina.ai/news/the-1950-2024-text-embeddings-evolution-poster\",\n",
    "    \"https://jina.ai/news/words-json-images-scenexplains-new-json-schema-builder\",\n",
    "    \"https://jina.ai/news/full-stack-rag-with-jina-embeddings-v2-and-llamaindex\",\n",
    "    \"https://jina.ai/news/a-magic-carpet-ride-building-vivid-product-stories-with-scenexplain\",\n",
    "    \"https://jina.ai/news/multi-agent-simulations-in-promptperfect-n-heads-are-better-than-one\",\n",
    "    \"https://jina.ai/news/a-tale-of-two-worlds-emnlp-2023-at-sentosa\",\n",
    "    \"https://jina.ai/news/graph-embedding-101-unraveling-the-magic-of-relational-data\",\n",
    "    \"https://jina.ai/news/fine-tuning-gpt-3-5-turbo-a-costly-mirage\",\n",
    "    \"https://jina.ai/news/the-boundless-horizon-of-ai-its-not-just-about-the-size\",\n",
    "    \"https://jina.ai/news/building-a-streaming-api-for-llama-2-real-time-ai-with-jina-and-docarray\",\n",
    "    \"https://jina.ai/news/training-smarter-not-harder-slimming-sentence-embeddings\",\n",
    "    \"https://jina.ai/news/beyond-pixels-to-prose-scenexplains-hearth-algorithm-breathes-audible-life-into-images\",\n",
    "    \"https://jina.ai/news/whats-new-in-promptperfect-new-optimizer-streaming-bulk-optimization\",\n",
    "    \"https://jina.ai/news/scenexplains-image-json-extract-structured-data-images-precision\",\n",
    "    \"https://jina.ai/news/embeddings-the-swiss-army-knife-of-ai\",\n",
    "    \"https://jina.ai/news/promptperfects-llm-database-blurring-boundaries-search-vs-generation\",\n",
    "    \"https://jina.ai/news/distilled-ai-using-large-models-to-teach-smaller-ones\",\n",
    "    \"https://jina.ai/news/do-you-truly-need-a-dedicated-vector-store\",\n",
    "    \"https://jina.ai/news/how-scenexplain-solves-video-to-text-comprehension\",\n",
    "    \"https://jina.ai/news/building-rag-with-jina-ai-and-superduperdb\",\n",
    "    \"https://jina.ai/news/precise-rag-with-jina-reranker-and-llamaindex\",\n",
    "    \"https://jina.ai/news/build-a-rag-system-with-jina-embeddings-and-qdrant\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "608d1359-bb9a-4b92-9244-8c2e0981e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(url):\n",
    "\n",
    "    url = f\"https://r.jina.ai/{url}\"\n",
    "\n",
    "    headers = {\n",
    "        \"X-Return-Format\": \"text\",\n",
    "        \"X-No-Cache\": \"true\",\n",
    "        \"X-Timeout\": \"1000\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bf831f06-1571-48e6-b5a7-40a996872b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# sometimes reader doesn't get the text\n",
    "def read_with_retry(url, retries=3, delay=2):\n",
    "    \"\"\"Attempt to read content from a URL, retrying up to `retries` times if content is empty.\"\"\"\n",
    "    attempt = 0\n",
    "    text = \"\"\n",
    "    \n",
    "    while attempt < retries:\n",
    "        print(f\"Attempt {attempt + 1} for {url}\")\n",
    "        try:\n",
    "            text = read(url)  # assuming `read(url)` fetches the text\n",
    "            if text:  # Check if the content is non-empty\n",
    "                break  # Exit loop if text is successfully fetched\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {url}: {e}\")\n",
    "        \n",
    "        attempt += 1\n",
    "        if attempt < retries:\n",
    "            time.sleep(delay)  # Optional: Delay between retries\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2b52eb7c-a588-490b-8ed2-e27036855f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2125338d-d83a-4151-a441-4034b4797e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 for https://jina.ai/news/reader-lm-small-language-models-for-cleaning-and-converting-html-to-markdown\n",
      "Attempt 1 for https://jina.ai/news/jina-colbert-v2-multilingual-late-interaction-retriever-for-embedding-and-reranking\n",
      "Attempt 1 for https://jina.ai/news/late-chunking-in-long-context-embedding-models\n",
      "Attempt 1 for https://jina.ai/news/the-what-and-why-of-text-image-modality-gap-in-clip-models\n",
      "Attempt 1 for https://jina.ai/news/by-hoovering-up-the-web-ai-is-poisoning-itself\n",
      "Attempt 1 for https://jina.ai/news/what-we-learned-at-icml2024-ft-plag-xrm-tinybenchmark-magiclens-prompt-sketching-etc\n",
      "Attempt 1 for https://jina.ai/news/jina-embeddings-and-reranker-on-azure-scalable-business-ready-ai-solutions\n",
      "Attempt 1 for https://jina.ai/news/having-it-both-ways-combining-bm25-with-ai-reranking\n",
      "Attempt 1 for https://jina.ai/news/smaller-faster-cheaper-jina-rerankers-turbo-and-tiny\n",
      "Attempt 1 for https://jina.ai/news/enhancing-search-results-with-jina-ais-reranker-api-in-myscale\n",
      "Attempt 1 for https://jina.ai/news/retrieve-jira-tickets-with-jina-reranker-and-haystack-20\n",
      "Attempt 1 for https://jina.ai/news/dspy-not-your-average-prompt-engineering\n",
      "Attempt 1 for https://jina.ai/news/elevating-youtube-scripts-with-promptperfect-ai-mastery-for-video-content-creators\n",
      "Attempt 1 for https://jina.ai/news/next-level-cloud-ai-jina-embeddings-and-rerankers-on-amazon-sagemaker\n",
      "Attempt 1 for https://jina.ai/news/click-worthy-content-with-promptperfect-ai-marketing-for-newsletters-and-social-media\n",
      "Attempt 1 for https://jina.ai/news/maximizing-search-relevancy-and-rag-accuracy-with-jina-reranker\n",
      "Attempt 1 for https://jina.ai/news/revolutionizing-bilingual-text-embeddings-with-multi-task-contrastive-learning\n",
      "Attempt 1 for https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search\n",
      "Attempt 1 for https://jina.ai/news/theres-a-time-and-a-place-unleashing-dynamic-variables-in-promptperfect\n",
      "Attempt 1 for https://jina.ai/news/dify-ai-integrates-jina-embeddings-for-rag\n",
      "Attempt 1 for https://jina.ai/news/jina-embeddings-v2-and-mongodb-atlas\n",
      "Attempt 1 for https://jina.ai/news/scenexplains-json-schema-store-automate-your-alt-text-and-more\n",
      "Attempt 1 for https://jina.ai/news/artificial-general-intelligence-is-cursed-and-science-fiction-isnt-helping\n",
      "Attempt 1 for https://jina.ai/news/jina-ai-8k-embedding-models-hit-aws-marketplace-for-on-prem-deployment\n",
      "Attempt 1 for https://jina.ai/news/scenexplains-ocr-beats-gpt-4v-hands-down-chinese-japanese-korean-arabic-hindi-and-more\n",
      "Attempt 1 for https://jina.ai/news/embeddings-in-depth\n",
      "Attempt 2 for https://jina.ai/news/embeddings-in-depth\n",
      "Attempt 3 for https://jina.ai/news/embeddings-in-depth\n",
      "Attempt 1 for https://jina.ai/news/look-up-in-the-sky-using-scenexplain-to-classify-land-use-from-satellite-data\n",
      "Attempt 1 for https://jina.ai/news/jina-embeddings-2-the-best-solution-for-embedding-long-documents\n",
      "Attempt 1 for https://jina.ai/news/case-study-revolutionizing-e-commerce-user-experience-and-streamlining-search-with-scenexplain\n",
      "Attempt 1 for https://jina.ai/news/the-1950-2024-text-embeddings-evolution-poster\n",
      "Attempt 1 for https://jina.ai/news/words-json-images-scenexplains-new-json-schema-builder\n",
      "Attempt 1 for https://jina.ai/news/full-stack-rag-with-jina-embeddings-v2-and-llamaindex\n",
      "Attempt 1 for https://jina.ai/news/a-magic-carpet-ride-building-vivid-product-stories-with-scenexplain\n",
      "Attempt 1 for https://jina.ai/news/multi-agent-simulations-in-promptperfect-n-heads-are-better-than-one\n",
      "Attempt 1 for https://jina.ai/news/a-tale-of-two-worlds-emnlp-2023-at-sentosa\n",
      "Attempt 1 for https://jina.ai/news/graph-embedding-101-unraveling-the-magic-of-relational-data\n",
      "Attempt 1 for https://jina.ai/news/fine-tuning-gpt-3-5-turbo-a-costly-mirage\n",
      "Attempt 1 for https://jina.ai/news/the-boundless-horizon-of-ai-its-not-just-about-the-size\n",
      "Attempt 1 for https://jina.ai/news/building-a-streaming-api-for-llama-2-real-time-ai-with-jina-and-docarray\n",
      "Attempt 1 for https://jina.ai/news/training-smarter-not-harder-slimming-sentence-embeddings\n",
      "Attempt 1 for https://jina.ai/news/beyond-pixels-to-prose-scenexplains-hearth-algorithm-breathes-audible-life-into-images\n",
      "Attempt 1 for https://jina.ai/news/whats-new-in-promptperfect-new-optimizer-streaming-bulk-optimization\n",
      "Attempt 1 for https://jina.ai/news/scenexplains-image-json-extract-structured-data-images-precision\n",
      "Attempt 1 for https://jina.ai/news/embeddings-the-swiss-army-knife-of-ai\n",
      "Attempt 1 for https://jina.ai/news/promptperfects-llm-database-blurring-boundaries-search-vs-generation\n",
      "Attempt 1 for https://jina.ai/news/distilled-ai-using-large-models-to-teach-smaller-ones\n",
      "Attempt 1 for https://jina.ai/news/do-you-truly-need-a-dedicated-vector-store\n",
      "Attempt 1 for https://jina.ai/news/how-scenexplain-solves-video-to-text-comprehension\n",
      "Attempt 1 for https://jina.ai/news/building-rag-with-jina-ai-and-superduperdb\n",
      "Attempt 1 for https://jina.ai/news/precise-rag-with-jina-reranker-and-llamaindex\n",
      "Attempt 1 for https://jina.ai/news/build-a-rag-system-with-jina-embeddings-and-qdrant\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "for url in urls:\n",
    "    doc = BlogPost(url=url)\n",
    "    doc.filename = os.path.basename(url)\n",
    "    # print(f\"Processing {doc.filename}\")\n",
    "    \n",
    "    doc.text = read_with_retry(url)\n",
    "\n",
    "    if len(doc.text.strip()) != 0:\n",
    "        docs.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a08be-82f7-445a-9d37-258b46f02308",
   "metadata": {},
   "source": [
    "### See how many failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5e420498-7b76-4a19-ae90-a646005bea77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls) - len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde851d5-d3d7-4137-936d-7f7835d1b0af",
   "metadata": {},
   "source": [
    "## Save as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b17c2884-8cb8-46e5-93df-c1c339bd50bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs-populated.pkl\", \"wb\") as file:\n",
    "    pickle.dump(docs, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9795d6-aefb-4cc0-8919-a7c24a740971",
   "metadata": {},
   "source": [
    "## Combine into bigger corpora for topic/q/a generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "98a9b04b-757f-440b-9169-f546caefc2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(lst, x):\n",
    "    \"\"\"Splits the given list into sublists of size x.\"\"\"\n",
    "    return [lst[i:i + x] for i in range(0, len(lst), x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d17cab46-96ae-45b0-950b-f1da5dd339ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_lists = split_list(docs, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "45bced44-1d2c-4ff6-a483-5e9209fdabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_strings(doc_list):\n",
    "    return '---'.join(doc.text for doc in doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ed5ffd67-c036-4a32-bd8a-55dcc7d659e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split docs into different batches, otherwise exceed GPT-4 turbo context window. Each batch is now under ~100k tokens acc to OpenAI tokenizer\n",
    "texts = []\n",
    "for i, lst in enumerate(split_lists, start=1):\n",
    "    concat_text = concat_strings(lst)\n",
    "    texts.append(concat_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0893287b-ab3c-43c2-98b1-40dd8c1ce2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d01e40-dedd-4427-b364-b176b015dcd3",
   "metadata": {},
   "source": [
    "## Generate topics, questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35160ff4-3f34-434e-9f26-8d2779f9c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain\n",
    "!pip install -q langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cce115dd-d679-40a9-9f07-b9a0860d3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "The user is going to upload several batches of blog posts. your job is to:\n",
    "- Generate five topics that are covered in the text\n",
    "- For each topic, generate five deep technical questions which can only be answered by reading the text\n",
    "- Provide answers to those questions in a manner similar to a RAG system\n",
    "\n",
    "Ensure your answers are accurate, detailed, and concise.\n",
    "\n",
    "Provide your output in a JSON structure as follows:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"topic\": \"topic_name\",\n",
    "    \"questions\": [\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"topic\": \"topic_name\",\n",
    "    \"questions\": [\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "      {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer\n",
    "      },\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "Return only pure JSON as output. Do not wrap the output in backticks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2bdaab09-ab58-430b-b662-82cc8188c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_BASE = \"https://api2.road2all.com/v1/\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-2024-08-06\",\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    openai_api_base=OPENAI_API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7aa1ccc5-5b69-46c8-b849-33e305d0b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def response_to_json(text):\n",
    "    # sometimes output is code-fenced\n",
    "    if text[0] == \"`\":\n",
    "        lines = text.split('\\n')\n",
    "        text = '\\n'.join(lines[1:-1])\n",
    "\n",
    "    json_output = json.loads(text)\n",
    "\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "36785756-97a2-482f-9507-29d10d7592f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(texts):\n",
    "    topics_qa = []\n",
    "    for i, text in enumerate(texts, start=1):\n",
    "        print(f\"Generating for text [{i}/{len(texts)}]\")\n",
    "        messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        (\"human\", texts[0]),\n",
    "        ]\n",
    "        response = llm.invoke(messages).content\n",
    "\n",
    "        response = response_to_json(response)\n",
    "        topics_qa.extend(response)\n",
    "    \n",
    "    return topics_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a998e0e6-c108-41cd-b670-3d1913a2e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating for text [1/3]\n",
      "Generating for text [2/3]\n",
      "Generating for text [3/3]\n"
     ]
    }
   ],
   "source": [
    "topics_questions_answers = generate_questions(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a22c6a55-6232-41e8-b2bd-8c542b2056bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics_questions_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283cbeb-484a-4824-87fd-338819ae2f8f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "712dd046-3548-43ac-8eca-bc9df64d085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"topics_questions_answers.pkl\", \"wb\") as file:\n",
    "    file.write(pickle.dumps(topics_questions_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd14492-9137-4501-be6f-1f080fc61254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
